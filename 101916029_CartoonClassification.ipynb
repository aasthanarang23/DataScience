{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-16T16:17:33.324007Z","iopub.execute_input":"2022-03-16T16:17:33.324344Z","iopub.status.idle":"2022-03-16T16:17:33.337808Z","shell.execute_reply.started":"2022-03-16T16:17:33.324263Z","shell.execute_reply":"2022-03-16T16:17:33.337209Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nimport cv2\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing.image import ImageDataGenerator\n#from tensorflow.keras.applications.vgg16 import VGG16\nfrom keras.models import Sequential\nfrom keras.layers import Activation, Dropout, Flatten, Dense\n#from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:17:33.339280Z","iopub.execute_input":"2022-03-16T16:17:33.339729Z","iopub.status.idle":"2022-03-16T16:17:35.755193Z","shell.execute_reply.started":"2022-03-16T16:17:33.339700Z","shell.execute_reply":"2022-03-16T16:17:35.754546Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"img_height=180\nimg_width=320\n\ntrain_path=\"../input/cartoon-classification/cartoon_classification/TRAIN\"\ntest_path=\"../input/cartoon-classification/cartoon_classification/TEST\"\n\nbatch_size = 8\ntrain_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    vertical_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1. / 255)\n   \ntrain_generator = train_datagen.flow_from_directory(\n    train_path,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical')\n\ntest_generator = test_datagen.flow_from_directory(\n    test_path,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical')\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:17:35.756396Z","iopub.execute_input":"2022-03-16T16:17:35.756597Z","iopub.status.idle":"2022-03-16T16:18:06.953641Z","shell.execute_reply.started":"2022-03-16T16:17:35.756570Z","shell.execute_reply":"2022-03-16T16:18:06.952588Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"mobile = tf.keras.applications.mobilenet.MobileNet()\nmobile.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:18:06.954917Z","iopub.execute_input":"2022-03-16T16:18:06.955158Z","iopub.status.idle":"2022-03-16T16:18:07.640380Z","shell.execute_reply.started":"2022-03-16T16:18:06.955127Z","shell.execute_reply":"2022-03-16T16:18:07.639103Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"x = mobile.layers[-6].output\noutput = Dense(units=10, activation='softmax')(x)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:18:07.642447Z","iopub.execute_input":"2022-03-16T16:18:07.642651Z","iopub.status.idle":"2022-03-16T16:18:07.655919Z","shell.execute_reply.started":"2022-03-16T16:18:07.642625Z","shell.execute_reply":"2022-03-16T16:18:07.655112Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from keras.models import Model, load_model\nmodel = Model(inputs=mobile.input, outputs=output)\nfor layer in model.layers[:-23]:\n    layer.trainable = False\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:18:07.657161Z","iopub.execute_input":"2022-03-16T16:18:07.657390Z","iopub.status.idle":"2022-03-16T16:18:07.710514Z","shell.execute_reply.started":"2022-03-16T16:18:07.657359Z","shell.execute_reply":"2022-03-16T16:18:07.709561Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:18:07.711926Z","iopub.execute_input":"2022-03-16T16:18:07.712169Z","iopub.status.idle":"2022-03-16T16:18:07.724738Z","shell.execute_reply.started":"2022-03-16T16:18:07.712136Z","shell.execute_reply":"2022-03-16T16:18:07.723720Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:18:07.726515Z","iopub.execute_input":"2022-03-16T16:18:07.726774Z","iopub.status.idle":"2022-03-16T16:18:07.734411Z","shell.execute_reply.started":"2022-03-16T16:18:07.726737Z","shell.execute_reply":"2022-03-16T16:18:07.733783Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"checkpoint_filepath = './'\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    save_weights_only=True,\n    monitor='val_accuracy',\n    mode='max',\n    save_best_only=True)\nhist=model.fit(x=train_generator,\n            steps_per_epoch=1500,\n            validation_data=test_generator,\n            validation_steps=220,\n            epochs=8,\n            verbose=1,\n            callbacks=[model_checkpoint_callback]\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:18:07.735359Z","iopub.execute_input":"2022-03-16T16:18:07.735564Z","iopub.status.idle":"2022-03-16T17:39:05.299072Z","shell.execute_reply.started":"2022-03-16T16:18:07.735537Z","shell.execute_reply":"2022-03-16T17:39:05.297815Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"\nmodel.load_weights(checkpoint_filepath)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T17:39:06.163022Z","iopub.execute_input":"2022-03-16T17:39:06.163735Z","iopub.status.idle":"2022-03-16T17:39:06.361232Z","shell.execute_reply.started":"2022-03-16T17:39:06.163697Z","shell.execute_reply":"2022-03-16T17:39:06.360472Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"fig1 = plt.gcf()\nplt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])\nplt.axis(ymin=0.4,ymax=1)\nplt.grid()\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend(['train', 'validation'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T17:39:05.627132Z","iopub.execute_input":"2022-03-16T17:39:05.627337Z","iopub.status.idle":"2022-03-16T17:39:05.876059Z","shell.execute_reply.started":"2022-03-16T17:39:05.627309Z","shell.execute_reply":"2022-03-16T17:39:05.874936Z"},"trusted":true},"execution_count":11,"outputs":[]}]}